{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_embeddings, train_labels, test_embeddings, k, distance_metric):\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(test_embeddings, train_embeddings)\n",
    "    elif distance_metric == 'cosine':\n",
    "        distances = cosine_distances(test_embeddings, train_embeddings)\n",
    "    \n",
    "    sorted_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    k_nearest_labels = train_labels[sorted_indices]\n",
    "    \n",
    "    # Majority voting using Counter\n",
    "    mode_labels = torch.mode(k_nearest_labels, dim=1)[0]  # Most frequent label per row\n",
    "    return mode_labels\n",
    "\n",
    "def classify(train_embeddings, train_labels, test_embeddings, test_labels, k_values, distance_metrics):\n",
    "    results = {}\n",
    "    train_embeddings, train_labels = torch.tensor(train_embeddings), torch.tensor(train_labels)\n",
    "    test_embeddings, test_labels = torch.tensor(test_embeddings), torch.tensor(test_labels)\n",
    "    \n",
    "    for k in k_values:\n",
    "        \"\"\" for metric in distance_metrics:\n",
    "            print(f'Classifying with k={k}, metric={metric}')\n",
    "            predicted_labels = knn(train_embeddings, train_labels, test_embeddings, k, metric)\n",
    "            accuracy = (predicted_labels == test_labels).float().mean().item()\n",
    "            results[(k, metric)] = accuracy \"\"\"\n",
    "        \n",
    "        \n",
    "        for metric in distance_metrics:\n",
    "            print(f'Classifying with k={k}, metric={metric}')\n",
    "            predicted_labels = knn(train_embeddings, train_labels, test_embeddings, k, metric)\n",
    "            accuracy = (predicted_labels == test_labels).float().mean().item()\n",
    "            print(f'Accuracy using text embeddings to predict labels with k={k} and distance metric={metric}: {accuracy}')\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "main",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: torch.Size([50000, 512])\n",
      "Text embeddings shape: torch.Size([10, 512])\n",
      "Test labels shape: torch.Size([10000])\n",
      "Train labels shape: torch.Size([50000])\n",
      "Test embeddings shape: torch.Size([10000, 512])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Load embeddings and labels from .pth files\n",
    "train_embeddings = torch.load('./SMAI_A1/train_embeddings.pth', map_location=torch.device('cpu'))\n",
    "train_labels = torch.load('./SMAI_A1/train_labels.pth', map_location=torch.device('cpu'))\n",
    "test_embeddings = torch.load('./SMAI_A1/test_embeddings.pth', map_location=torch.device('cpu'))\n",
    "test_labels = torch.load('./SMAI_A1/test_labels.pth', map_location=torch.device('cpu'))\n",
    "text_embeddings = torch.load('./SMAI_A1/text_embedding.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "print(\"Train embeddings shape:\", train_embeddings.shape)\n",
    "print(\"Text embeddings shape:\", text_embeddings.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test embeddings shape:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cc2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_371234/3602291682.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_embeddings, train_labels = torch.tensor(train_embeddings), torch.tensor(train_labels)\n",
      "/tmp/ipykernel_371234/3602291682.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_embeddings, test_labels = torch.tensor(test_embeddings), torch.tensor(test_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying with k=1, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=1 and distance metric=euclidean: 0.9047999978065491\n",
      "Classifying with k=1, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=1 and distance metric=cosine: 0.9047999978065491\n",
      "Classifying with k=5, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=5 and distance metric=euclidean: 0.9182000160217285\n",
      "Classifying with k=5, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=5 and distance metric=cosine: 0.9182000160217285\n",
      "Classifying with k=10, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=10 and distance metric=euclidean: 0.9193999767303467\n",
      "Classifying with k=10, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=10 and distance metric=cosine: 0.9193999767303467\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_371234/3602291682.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_embeddings, train_labels = torch.tensor(train_embeddings), torch.tensor(train_labels)\n",
      "/tmp/ipykernel_371234/3602291682.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_embeddings, test_labels = torch.tensor(test_embeddings), torch.tensor(test_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying with k=1, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=1 and distance metric=euclidean: 0.9047999978065491\n",
      "Classifying with k=1, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=1 and distance metric=cosine: 0.9047999978065491\n",
      "Classifying with k=5, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=5 and distance metric=euclidean: 0.9182000160217285\n",
      "Classifying with k=5, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=5 and distance metric=cosine: 0.9182000160217285\n",
      "Classifying with k=10, metric=euclidean\n",
      "Accuracy using text embeddings to predict labels with k=10 and distance metric=euclidean: 0.9193999767303467\n",
      "Classifying with k=10, metric=cosine\n",
      "Accuracy using text embeddings to predict labels with k=10 and distance metric=cosine: 0.9193999767303467\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "k_values = [1, 5, 10]\n",
    "distance_metrics = ['euclidean', 'cosine']\n",
    "\n",
    "results = classify(train_embeddings, train_labels, test_embeddings, test_labels, k_values, distance_metrics)\n",
    "print(results)\n",
    "\n",
    "k_values = [1, 5, 10]\n",
    "distance_metrics = ['euclidean', 'cosine']\n",
    "\n",
    "results = classify(train_embeddings, train_labels, test_embeddings, test_labels, k_values, distance_metrics)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0b220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using text embeddings with k=1: 0.8781\n"
     ]
    }
   ],
   "source": [
    "\n",
    "distances = euclidean_distances(test_embeddings, text_embeddings)\n",
    "nearest_indices = np.argmin(distances, axis=1)\n",
    "predicted_labels = nearest_indices\n",
    "accuracyy = (predicted_labels == test_labels).float().mean().item()\n",
    "print(f\"Accuracy using text embeddings with k=1: {accuracyy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a10fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_371234/3400547285.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_embeddings = torch.tensor(train_embeddings)\n",
      "/tmp/ipykernel_371234/3400547285.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "/tmp/ipykernel_371234/3400547285.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_embeddings = torch.tensor(test_embeddings)\n",
      "/tmp/ipykernel_371234/3400547285.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = torch.tensor(test_labels)\n",
      "/tmp/ipykernel_371234/3400547285.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text_embeddings = torch.tensor(text_embeddings)\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy arrays to torch tensors\n",
    "train_embeddings = torch.tensor(train_embeddings)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_embeddings = torch.tensor(test_embeddings)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "text_embeddings = torch.tensor(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d09f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(predictions, true_labels):\n",
    "    ranks = []\n",
    "    for true_label, pred in zip(true_labels, predictions):\n",
    "        try:\n",
    "            rank = pred.tolist().index(true_label) + 1\n",
    "            ranks.append(1 / rank)\n",
    "        except ValueError:\n",
    "            ranks.append(0)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "def precision_at_k(retrieved_indices, true_indices, k):\n",
    "    relevant = np.isin(retrieved_indices[:k], true_indices)\n",
    "    return np.sum(relevant) / k\n",
    "\n",
    "def hit_rate(retrieved_indices, true_indices):\n",
    "    return np.any(np.isin(retrieved_indices, true_indices)).astype(int)\n",
    "\n",
    "def retrieve_nearest_neighbors(query_embeddings, train_embeddings, k=100, distance_metric='euclidean'):\n",
    "    if distance_metric == 'euclidean':\n",
    "        distances = euclidean_distances(query_embeddings, train_embeddings)\n",
    "    elif distance_metric == 'cosine':\n",
    "        distances = cosine_distances(query_embeddings, train_embeddings)\n",
    "    \n",
    "    sorted_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    return sorted_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66e336",
   "metadata": {},
   "source": [
    "# Text to Image Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "192e6c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.1622\n",
      "Precision@100: 10.0000\n",
      "Hit Rate: 1.0000\n"
     ]
    }
   ],
   "source": [
    "distances = euclidean_distances(text_embeddings, test_embeddings)\n",
    "\n",
    "# Retrieve the 100 nearest embeddings for each test embedding\n",
    "k = 100\n",
    "nearest_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "nearest_labels = train_labels[nearest_indices]\n",
    "\n",
    "# Calculate metrics\n",
    "true_labels = np.arange(10)\n",
    "mrr1 = calculate_mrr(nearest_labels, true_labels)\n",
    "precision = precision_at_k(nearest_labels, true_labels, k)\n",
    "hit_rate_value = hit_rate(nearest_labels, true_labels)\n",
    "\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr1:.4f}\")\n",
    "print(f\"Precision@{k}: {precision:.4f}\")\n",
    "print(f\"Hit Rate: {hit_rate_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99d9ea",
   "metadata": {},
   "source": [
    "# Image to Image Retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "065858d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.9348\n",
      "Precision@100: 100.0000\n",
      "Hit Rate: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute distances between test embeddings and all train embeddings\n",
    "distances = euclidean_distances(test_embeddings, train_embeddings)\n",
    "\n",
    "# Retrieve the 100 nearest embeddings for each test embedding\n",
    "k = 100\n",
    "nearest_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "nearest_labels = train_labels[nearest_indices]\n",
    "\n",
    "# Calculate metrics\n",
    "mrr_img_t_img = calculate_mrr(nearest_labels, test_labels)\n",
    "precision = precision_at_k(nearest_labels, test_labels, k)\n",
    "hit_rate_value = hit_rate(nearest_labels, test_labels)\n",
    "\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr_img_t_img:.4f}\")\n",
    "print(f\"Precision@100: {precision:.4f}\")\n",
    "print(f\"Hit Rate: {hit_rate_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d82db73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, num_hyperplanes, embedding_dim):\n",
    "        self.num_hyperplanes = num_hyperplanes\n",
    "        self.hyperplanes = np.random.randn(num_hyperplanes, embedding_dim)  # Random hyperplanes\n",
    "\n",
    "    def compute_hash(self, embeddings):\n",
    "        projections = np.dot(embeddings, self.hyperplanes.T)  # Compute dot products\n",
    "        return (projections > 0).astype(int)  # Convert to binary hash\n",
    "\n",
    "    def index_embeddings(self, embeddings):\n",
    "        hash_buckets = defaultdict(list)\n",
    "        hashes = self.compute_hash(embeddings)\n",
    "        for idx, h in enumerate(hashes):\n",
    "            hash_tuple = tuple(h)\n",
    "            hash_buckets[hash_tuple].append(idx)\n",
    "        return hash_buckets\n",
    "\n",
    "    def retrieve(self, query_embedding, hash_buckets, k=5):\n",
    "        query_hash = tuple(self.compute_hash(query_embedding.reshape(1, -1))[0])\n",
    "        if query_hash in hash_buckets:\n",
    "            candidates = hash_buckets[query_hash]\n",
    "        else:\n",
    "            candidates = []\n",
    "        return candidates[:k]  # Return up to k nearest candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eaab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings (assuming already available in variables)\n",
    "embedding_dim = train_embeddings.shape[1]\n",
    "num_hyperplanes_list = [5, 10, 20]  # Different number of hyperplanes\n",
    "\n",
    "for num_hyperplanes in num_hyperplanes_list:\n",
    "    lsh = LSH(num_hyperplanes, embedding_dim)\n",
    "    hash_buckets = lsh.index_embeddings(train_embeddings.numpy())\n",
    "    \n",
    "    # Plot histogram of bucket sizes\n",
    "    bucket_sizes = [len(v) for v in hash_buckets.values()]\n",
    "    plt.hist(bucket_sizes, bins=30, alpha=0.6, label=f'{num_hyperplanes} hyperplanes')\n",
    "    plt.xlabel(\"Bucket Size\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of Samples in Buckets\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Perform image retrieval for k=5\n",
    "    retrieved_indices = []\n",
    "    actual_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for i in range(len(test_embeddings)):\n",
    "        retrieved = lsh.retrieve(test_embeddings[i], hash_buckets, k=5)\n",
    "        retrieved_indices.append(retrieved)\n",
    "        \n",
    "        if retrieved:\n",
    "            actual_labels.extend([test_labels[i]] * len(retrieved))\n",
    "            predicted_labels.extend(train_labels[retrieved])\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(actual_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(actual_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    print(f'Hyperplanes: {num_hyperplanes} | Precision: {precision:.4f} | Recall: {recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8b638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai_as1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
